{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-yaVlzX7zKC"
   },
   "source": [
    "### **Vetorização**\n",
    "\n",
    "\n",
    "A vetorização dos dados permite transformá-los da linguagem humana e não estruturada para uma maneira mais compreensível ao computador, ou seja, **codificando em números**, sendo possível assim associar cada um dos textos a um sentido e significado delimitados. \n",
    "\n",
    "\n",
    "O **Bag of Words**, ou sacola de palavras em português, é uma lista que contém todas as palavras que estão nos textos de maneira não repetida e tem papel importante para **identificar as palavras mais recorrentes** e entender se elas agregam algum sentimento.\n",
    "\n",
    "\n",
    "Aqui no spark o bag of words não é representado por uma matriz do vocabulário como no python, e sim com uma estrutura específica que cria uma **estrutura especifica** que faciliar a compreensão nos modelos. \n",
    "\n",
    "Alternativas para vetorização: matriz_esparsa, countvectorizer, Hashing TF...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDr8oqvy7FcR"
   },
   "outputs": [],
   "source": [
    "# retomando nosso exemplo\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"texto_final\", outputCol=\"CountVec\")\n",
    "model = cv.fit(df)\n",
    "df = model.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1659317660498,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "rh_YSrFW7sZU",
    "outputId": "cb2ffe0f-9e3c-4f79-867f-2ac30df56b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+-------------------------------------+\n",
      "|texto_final                            |CountVec                             |\n",
      "+---------------------------------------+-------------------------------------+\n",
      "|[spark, é, ótimo, nlp, spark, é, fácil]|(7,[0,1,3,5,6],[2.0,2.0,1.0,1.0,1.0])|\n",
      "|[spark, mllib, ajuda]                  |(7,[0,2,4],[1.0,1.0,1.0])            |\n",
      "|[mllib, spark, ajuda, é, fácil]        |(7,[0,1,2,3,4],[1.0,1.0,1.0,1.0,1.0])|\n",
      "+---------------------------------------+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('texto_final', 'CountVec').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1659317660499,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "Uif5vtd-iLoE",
    "outputId": "b705648b-28a3-4ffd-b23b-e023784c2036"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark', 'é', 'mllib', 'fácil', 'ajuda', 'nlp', 'ótimo']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quem são as palavras \n",
    "model.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJASiJlCLOIh"
   },
   "source": [
    "#### **[CountVector](https://spark.apache.org/docs/3.2.1/api/python/reference/api/pyspark.ml.feature.CountVectorizer.html)**: Frequência das palavras em cada\n",
    "\n",
    "Para cada observação é gerado vetor com a seguintes estrutura: \\\\\n",
    " `[número de features, [cód. das palavras na ordem do vocabulário],[frequência de cada palavra]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25398,
     "status": "ok",
     "timestamp": 1659317685892,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "hqgxSUnY-1Li",
    "outputId": "137d6757-09a9-4b2c-d5c2-a24d00bd5b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         texto_final|            CountVec|\n",
      "+--------------------+--------------------+\n",
      "|[mr, costner, dra...|(216710,[0,7,8,11...|\n",
      "|[example, majorit...|(216710,[1,2,3,8,...|\n",
      "|[first, hate, mor...|(216710,[0,2,4,11...|\n",
      "|[even, beatles, w...|(216710,[0,1,2,4,...|\n",
      "|[brass, pictures,...|(216710,[1,3,5,8,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Countvectorizer\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "cv = CountVectorizer(inputCol=\"texto_final\", outputCol=\"CountVec\")\n",
    "model = cv.fit(feature_data)\n",
    "countVectorizer_features = model.transform(feature_data)\n",
    "\n",
    "countVectorizer_features.select('texto_final','CountVec').limit(5).show()#truncate=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sB_XxScLTla"
   },
   "source": [
    "#### **[Hashing TF](https://spark.apache.org/docs/3.2.1/api/python/reference/api/pyspark.ml.feature.HashingTF.html)**: alternativa para o Countvector\n",
    "\n",
    "É gerado a mesma estrutura, entretando aqui limitamos o número de palavras contabilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIOOFIa45jQf"
   },
   "outputs": [],
   "source": [
    "# Hashing TF\n",
    "# Hashing TF é uma opção alternativa para o countvector que limita a quantidade de palavras, no caso, 50 palavras diferentes serão contadas. #numFeatures=1000\n",
    "from pyspark.ml.feature import HashingTF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"texto_final\", outputCol=\"hashingTF\")\n",
    "hashingTF.setNumFeatures(50)\n",
    "\n",
    "HTFfeaturizedData = hashingTF.transform(countVectorizer_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1659317686181,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "WAp3d2Kr-wYE",
    "outputId": "2ea173c0-e908-4171-9cc6-148cf0b52e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         texto_final|           hashingTF|\n",
      "+--------------------+--------------------+\n",
      "|[mr, costner, dra...|(50,[0,5,6,7,8,10...|\n",
      "|[example, majorit...|(50,[0,1,2,3,4,5,...|\n",
      "|[first, hate, mor...|(50,[0,1,2,3,5,6,...|\n",
      "|[even, beatles, w...|(50,[0,1,2,3,4,5,...|\n",
      "|[brass, pictures,...|(50,[0,1,2,3,4,5,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HTFfeaturizedData.select(\"texto_final\", \"hashingTF\").limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT6ThIXvLPHb"
   },
   "source": [
    "#### **TF-IDF**: estabelecendo pesos\n",
    "\n",
    "O TF-IDF não apenas contabiliza as diferentes palavras, mas também gera pesos para cada um a partir da predomância nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oanFmBnaDEsz"
   },
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(inputCol=\"hashingTF\", outputCol=\"features\")\n",
    "idfModel = idf.fit(HTFfeaturizedData)\n",
    "TFIDFfeaturizedData = idfModel.transform(HTFfeaturizedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1659317702229,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "XBaQVX8HDE3S",
    "outputId": "bf847a9c-4972-4403-98ac-4455a1fe67a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|texto_final                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[mr, costner, dragged, movie, far, longer, necessary, aside, terrific, sea, rescue, sequences, care, characters, us, ghosts, closet, costners, character, realized, early, forgotten, much, later, time, care, character, really, care, cocky, overconfident, ashton, kutcher, problem, comes, kid, thinks, hes, better, anyone, else, around, shows, signs, cluttered, closet, obstacle, appears, winning, costner, finally, well, past, half, way, point, stinker, costner, tells, us, kutchers, ghosts, told, kutcher, driven, best, prior, inkling, foreshadowing, magic, keep, turning, hour]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |(50,[0,5,6,7,8,10,11,12,13,15,16,17,19,21,22,23,24,25,26,27,29,30,31,33,34,35,37,38,39,40,41,42,43,44,47,48,49],[0.22233514383283537,0.1998375969275785,0.17619398783498014,0.5587548927975542,0.5741244698743148,1.5157760793134183,1.307304913409321,0.1603567151189746,0.20230972495725574,0.31029723321704944,1.581846945779354,0.9550285132417945,0.248197000328582,0.42671641869152205,1.382464882404761,0.21807654777114394,0.2690668220783183,0.2519876373319553,0.21421166317304804,0.3778202733257666,0.6544375621431859,0.2057561660166335,0.30481136565707384,0.5127868952107937,0.19643606542499614,0.4586076262978574,0.25388835783440905,0.22549670195156435,0.11406976048237878,0.21503859617595494,0.23404484976189782,0.4899776023049222,0.2358093530262909,0.2981975270523391,0.4754103706524901,0.8841473458754796,0.5629482546646647])                                                                                                                                                                                                                                  |\n",
      "|[example, majority, action, films, generic, boring, theres, really, nothing, worth, watching, complete, waste, barelytapped, talents, icet, ice, cube, whove, proven, many, times, capable, acting, acting, well, dont, bother, one, go, see, new, jack, city, ricochet, watch, new, york, undercover, icet, boyz, n, hood, higher, learning, friday, ice, cube, see, real, deal, icets, horribly, cliched, dialogue, alone, makes, film, grate, teeth, im, still, wondering, heck, bill, paxton, film, heck, always, play, exact, character, aliens, onward, every, film, ive, seen, bill, paxton, playing, exact, irritating, character, least, aliens, character, died, made, somewhat, gratifyingoverall, secondrate, action, trash, countless, better, films, see, really, want, see, one, watch, judgement, night, practically, carbon, copy, better, acting, better, script, thing, made, worth, watching, decent, hand, camera, , cinematography, almost, refreshing, comes, close, making, horrible, film, , quite, 410]                                                                                                                                                                                                                                                                                  |(50,[0,1,2,3,4,5,6,7,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,27,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,47,48,49],[1.778681150662683,0.3014986085241636,1.0586950886205537,0.502030443068144,0.9785089236023529,0.799350387710314,0.3523879756699603,0.5587548927975542,0.5741244698743148,0.7379941985337378,0.5684160297425318,0.9804786850569909,0.9621402907138475,0.3943463985674309,0.6205944664340989,0.4519562702226726,2.148814154794038,0.5321097023783236,0.248197000328582,0.7628275419746108,2.073697323607141,0.8723061910845757,0.2690668220783183,0.5039752746639106,0.1889101366628833,0.6544375621431859,0.2057561660166335,1.2192454626282954,0.509288884790927,0.7691803428161905,0.7857442616999846,1.1465190657446436,0.25388835783440905,0.4509934039031287,0.34220928144713636,0.4300771923519099,0.46808969952379564,0.7349664034573833,0.7074280590788727,0.5963950541046782,0.80114827310616,0.23770518532624504,0.8841473458754796,0.5629482546646647])                                                                                            |\n",
      "|[first, hate, moronic, rappers, couldnt, act, gun, pressed, foreheads, curse, shoot, acting, like, clichã©e, version, gangstersthe, movie, doesnt, take, five, minutes, explain, going, already, warehouse, single, sympathetic, character, movie, except, homeless, guy, also, one, half, brainbill, paxton, william, sadler, hill, billies, sadlers, character, much, villain, gangsters, didnt, like, right, startthe, movie, filled, pointless, violence, walter, hills, specialty, people, falling, windows, glass, flying, everywhere, pretty, much, plot, big, problem, root, noone, everybody, dies, except, paxton, homeless, guy, everybody, get, deservethe, two, black, people, act, homeless, guy, junkie, theyre, actors, profession, annoying, ugly, brain, dead, rappersstay, away, crap, watch, 48, hours, 1, 2, instead, lest, characters, care, sense, humor, nothing, real, actors, cast]                                                                                                                                                                                                                                                                                                                                                                                                      |(50,[0,1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,19,20,21,22,23,24,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,47,48,49],[0.22233514383283537,0.9044958255724909,0.35289836287351795,0.08367174051135734,0.399675193855157,0.3523879756699603,0.37250326186503613,0.2870622349371574,0.7379941985337378,0.3789440198283546,0.9804786850569909,0.801783575594873,0.6069291748717672,0.3943463985674309,0.15514861660852472,0.2259781351113363,0.9550285132417945,0.496394000657164,1.5256550839492216,0.8534328373830441,0.34561622060119024,0.43615309554228787,0.8072004662349548,0.4284233263460961,0.3778202733257666,0.8412091861668733,0.6544375621431859,1.234536996099801,0.30481136565707384,0.509288884790927,0.5127868952107937,0.7857442616999846,0.2293038131489287,0.39452636797311785,0.25388835783440905,0.676490105854693,0.6844185628942727,0.6451157885278649,0.7021345492856934,0.7349664034573833,0.8945925811570172,0.40057413655308,0.9508207413049802,1.4735789097924659,0.28147412733233235])                                                             |\n",
      "|[even, beatles, write, songs, everyone, liked, although, walter, hill, moptop, hes, second, none, comes, thought, provoking, action, movies, nineties, came, social, platforms, changing, music, film, emergence, rapper, turned, movie, star, full, swing, acting, took, back, seat, mans, overpowering, regional, accent, transparent, acting, one, many, icet, movies, saw, kid, loved, watch, later, cringe, bill, paxton, william, sadler, firemen, basic, lives, burning, building, tenant, go, flames, hands, map, gold, implications, hand, walter, quickly, neatly, setting, main, characters, location, fault, everyone, involved, turning, lameo, performances, icet, cube, must, red, hot, time, ive, enjoyed, careers, rappers, opinion, fell, flat, movie, ninety, minutes, one, guy, ridiculously, turning, back, guy, point, find, locked, multiple, states, disbelief, movie, documentary, wont, waste, time, recounting, stupid, plot, twists, movie, many, led, nowhere, got, feeling, watching, everyone, set, sord, confused, playing, things, cuff, two, things, still, enjoy, one, involves, scene, needle, sadlers, huge, 45, pistol, bottom, line, movie, like, dominos, pizza, yeah, ill, eat, im, hungry, dont, feel, like, cooking, im, well, aware, tastes, like, crap, 3, stars, meh]|(50,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49],[0.44467028766567074,0.3014986085241636,0.7057967257470359,0.33468696204542936,0.48925446180117643,0.799350387710314,0.7047759513399205,0.9312581546625903,0.5741244698743148,1.4759883970674756,1.5157760793134183,0.6536524567046605,0.9621402907138475,0.809238899829023,0.3943463985674309,0.9308916996511483,0.2259781351113363,0.7162713849313459,0.7981645535674853,2.669896396911138,0.42671641869152205,0.6912324412023805,1.7446123821691515,0.5381336441566366,0.7559629119958658,0.6426349895191441,0.3778202733257666,0.28040306205562443,0.9816563432147789,1.4402931621164345,0.6096227313141477,0.7639333271863906,0.5127868952107937,0.9821803271249807,1.1465190657446436,0.7890527359462357,0.5077767156688181,0.676490105854693,0.6844185628942727,0.21503859617595494,0.7021345492856934,1.4699328069147666,1.4148561181577455,0.7454938176308478,2.0028706827654,0.9508207413049802,0.5894315639169864,1.1258965093293294])|\n",
      "|[brass, pictures, movies, fitting, word, really, somewhat, brassy, alluring, visual, qualities, reminiscent, expensive, high, class, tv, commercials, unfortunately, brass, pictures, feature, films, pretense, wanting, entertain, viewers, two, hours, fail, miserably, undeniable, rather, soft, flabby, steamy, erotic, qualities, non, withstandingsenso, 45, remake, film, luchino, visconti, title, alida, valli, farley, granger, lead, original, tells, story, senseless, love, lust, around, venice, italian, wars, independence, brass, moved, action, 19th, 20th, century, 1945, exact, mussolini, murals, men, black, shirts, german, uniforms, tattered, garb, partisans, window, dressing, historic, context, completely, negligibleanna, galiena, plays, attractive, aristocratic, woman, falls, amoral, ss, guy, always, puts, much, lipstick, attractive, versatile, well, trained, italian, actress, clearly, material, wide, range, facial, expressions, signalling, boredom, loathing, delight, fear, hate, , ecstasy, best, reason, watch, picture, worth, two, stars, endures, basically, trashy, stuff, astonishing, amount, dignity, wish, really, good, parts, come, along, really, deserves]                                                                                            |(50,[0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],[0.22233514383283537,0.3014986085241636,1.0586950886205537,0.251015221534072,0.24462723090058822,0.399675193855157,0.5285819635049405,0.7450065237300723,0.8611867048114721,0.1894720099141773,0.3268262283523303,0.801783575594873,1.0115486247862786,1.1830391957022928,0.6205944664340989,0.6779344053340088,0.9550285132417945,1.0642194047566471,0.496394000657164,0.7628275419746108,1.0368486618035706,0.8723061910845757,0.5381336441566366,0.5039752746639106,0.8568466526921922,0.7556405466515332,1.402015310278122,0.6544375621431859,0.6172684980499005,1.2192454626282954,0.2546444423954635,0.7691803428161905,0.5893081962749884,0.6879114394467861,0.39452636797311785,1.2694417891720453,0.22549670195156435,0.45627904192951513,1.0751929808797747,0.46808969952379564,0.7349664034573833,0.2358093530262909,1.0436913446831868,0.40057413655308,0.3510872108597927,0.7131155559787351,0.5894315639169864,1.688844763993994])|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TFIDFfeaturizedData.select('texto_final', 'features').limit(5).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4zF6PSoSLnM"
   },
   "source": [
    "#### **Codificando**: variável resposta.\n",
    "Lembrando que ensinaremos que todas essas palavras estarão associadas ao sentimento do depoimento, positivo ou negativo, entretando precisamos codificar `neg` e `pos` para 0 e 1 e podemos usar o `StringIndexer`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1878,
     "status": "ok",
     "timestamp": 1659317704103,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "ww7cfiHCpWtZ",
    "outputId": "b791ca1b-f8b3-4846-aac2-ec6bc5ec43dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|      pos|24694|\n",
      "|      neg|24765|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lembra que nosso dados estão em texto? Aqui no Pyspark precisamos converter para número e faremos isso com o stringindexer\n",
    "\n",
    "TFIDFfeaturizedData.groupBy('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRhJvz0IoOLi"
   },
   "outputs": [],
   "source": [
    "# Codificando a variável resposta.\n",
    "# 1. replace\n",
    "# 2. stringindexer (sentiment -> label)\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "stringindexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
    "dados = stringindexer.fit(dados).transform(dados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1764,
     "status": "ok",
     "timestamp": 1659317707843,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "Fxt17zD4oSch",
    "outputId": "e82ddc5c-927a-4415-a5e1-234111677319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|sentiment|label|count|\n",
      "+---------+-----+-----+\n",
      "|      pos|  1.0|24694|\n",
      "|      neg|  0.0|24765|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quem é 0 e quem é 1?\n",
    "dados.groupBy(['sentiment','label']).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYodI0WWUXUM"
   },
   "source": [
    "#### **Pipeline**: Transformação dos dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPrrzNMsUTJK"
   },
   "outputs": [],
   "source": [
    "# Unindo nossas transformações.\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"texto_limpo\", outputCol=\"tokens\")\n",
    "stopwords = StopWordsRemover(inputCol=\"tokens\", outputCol=\"texto_final\")\n",
    "hashingTF = HashingTF(inputCol=stopwords.getOutputCol(), outputCol=\"HTF\", numFeatures=1000)\n",
    "tfidf = IDF(inputCol=\"HTF\", outputCol=\"features\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages = [tokenizer,stopwords, hashingTF, tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fsn6vgYrUTaW"
   },
   "outputs": [],
   "source": [
    "dados_transformados = pipeline.fit(dados).transform(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1659317727365,
     "user": {
      "displayName": "Ana Duarte",
      "userId": "09192327203072793599"
     },
     "user_tz": 180
    },
    "id": "B5bC1RiNUTd6",
    "outputId": "eb974af6-0c43-4d2c-e62e-603d11f9ed59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+---------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|             text_en|             text_pt|sentiment|         texto_regex|         texto_limpo|label|              tokens|         texto_final|                 HTF|            features|\n",
      "+---+--------------------+--------------------+---------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1|Once again Mr. Co...|Mais uma vez, o S...|      neg|Once again Mr Cos...|Once again Mr Cos...|  0.0|[once, again, mr,...|[mr, costner, dra...|(1000,[10,21,34,4...|(1000,[10,21,34,4...|\n",
      "|  2|This is an exampl...|Este é um exemplo...|      neg|This is an exampl...|This is an exampl...|  0.0|[this, is, an, ex...|[example, majorit...|(1000,[0,3,11,12,...|(1000,[0,3,11,12,...|\n",
      "|  3|First of all I ha...|Primeiro de tudo ...|      neg|First of all I ha...|First of all I ha...|  0.0|[first, of, all, ...|[first, hate, mor...|(1000,[1,7,33,38,...|(1000,[1,7,33,38,...|\n",
      "|  4|Not even the Beat...|Nem mesmo os Beat...|      neg|Not even the Beat...|Not even the Beat...|  0.0|[not, even, the, ...|[even, beatles, w...|(1000,[0,3,10,12,...|(1000,[0,3,10,12,...|\n",
      "|  5|Brass pictures mo...|Filmes de fotos d...|      neg|Brass pictures mo...|Brass pictures mo...|  0.0|[brass, pictures,...|[brass, pictures,...|(1000,[3,6,7,11,3...|(1000,[3,6,7,11,3...|\n",
      "+---+--------------------+--------------------+---------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados_transformados.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfeUbV-J2YD_"
   },
   "source": [
    "### **Modelo**\n",
    "\n",
    "Nosso objetivo é consguir identificar um comentário negativo ou positivo, para isso precisamos criar um modelo em que o computador consiga classificar os depoimentos. Agora que já processamos nossos dados podemos construir um **modelo de classificação**, veja alguma opções:\n",
    "\n",
    "* Regressão Logística\n",
    "* Árvore de Decisão\n",
    "* Florestas Aleatórias\n",
    "* GX boost\n",
    "* entre outros...\n",
    "\n",
    "Para testar nossos dados usaremos todos os procedimentos realizados em Limpeza e processamento dos dados e a vetorização que estabelece pesos para as palavras construidas a partir do TF-IDF.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj7YE5Dnu-fv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs8FxFdZ2Ys6"
   },
   "source": [
    "#### **Amostra e Treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxRQJI8QwFi_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oe8uAEK1Gawe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhL4rZs4zceJ+uLlFe3kET",
   "collapsed_sections": [],
   "mount_file_id": "1lVCE2igXU4fi93JoBpQsJzHb8AV9r4fw",
   "name": "Projeto - Aula 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
